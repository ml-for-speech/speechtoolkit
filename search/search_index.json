{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Introduction SpeechToolkit is an all-in-one, end-to-end toolkit for ML in speech. It aims to simplify the usage of text-to-speech, automatic speech recognition, and voice conversion models. Why SpeechToolkit? Almost every model uses a different Python API. If you wanted to integrate them into your project, you'd need to write customized code for the model. Switching to a different model would require significant changes. SpeechToolkit aims to solve this by providing a centralized, unified, easy-to-use Python API for speech models. Instead of having to rewrite your program to support a new model, you can simply change a couple lines of code with SpeechToolkit. In addition, SpeechToolkit packages these models into a simple, PyPI-installable package. This not only makes code management easier, but also can help mitigate potential licensing issues. Packages SpeechToolkit supports many different third-party open-access models, as well as some models developed by ML for Speech. While these models are mostly available through the SpeechToolkit package, we've packaged many of these models individually if you don't want to use the SpeechToolkit library. Get Started Visit the Getting Started page to get started!","title":"Introduction"},{"location":"#introduction","text":"SpeechToolkit is an all-in-one, end-to-end toolkit for ML in speech. It aims to simplify the usage of text-to-speech, automatic speech recognition, and voice conversion models.","title":"Introduction"},{"location":"#why-speechtoolkit","text":"Almost every model uses a different Python API. If you wanted to integrate them into your project, you'd need to write customized code for the model. Switching to a different model would require significant changes. SpeechToolkit aims to solve this by providing a centralized, unified, easy-to-use Python API for speech models. Instead of having to rewrite your program to support a new model, you can simply change a couple lines of code with SpeechToolkit. In addition, SpeechToolkit packages these models into a simple, PyPI-installable package. This not only makes code management easier, but also can help mitigate potential licensing issues.","title":"Why SpeechToolkit?"},{"location":"#packages","text":"SpeechToolkit supports many different third-party open-access models, as well as some models developed by ML for Speech. While these models are mostly available through the SpeechToolkit package, we've packaged many of these models individually if you don't want to use the SpeechToolkit library.","title":"Packages"},{"location":"#get-started","text":"Visit the Getting Started page to get started!","title":"Get Started"},{"location":"examples/","text":"Examples Text-to-Speech from speechtoolkit.tts import SingleSpeakerStyleTTS2Model model = SingleSpeakerStyleTTS2Model() model.infer_to_file('Hello, this is a test', 'out.wav') Multi-speaker StyleTTS 2 with zero-shot voice cloning: from speechtoolkit.tts import MultiSpeakerStyleTTS2Model model = MultiSpeakerStyleTTS2Model() model.infer_to_file('Hello, this is a test', 'sample.wav', 'out.wav') Automatic Speech Recognition from speechtoolkit.asr import WhisperModel model = WhisperModel() model.infer_file('audio.wav') With a larger model: from speechtoolkit.asr import WhisperModel model = WhisperModel('medium') model.infer_file('audio.wav') With DistilWhisper: from speechtoolkit.asr import DistilWhisperModel model = DistilWhisperModel() model.infer_file('audio.wav') Voice Conversion from speechtoolkit.vc import LVC vc = LVC(device='auto') vc.infer_file( 'original.wav', 'sample.wav', 'out.wav' ) Language Classification from speechtoolkit.classification.languageclassification import WhisperLanguageClassifierModel lc = WhisperLanguageClassifierModel() lc.infer_file('audio.wav') # 'en' Accent Classification from speechtoolkit.classification.accentclassification import EdAccAccentClassifierModel ac = EdAccAccentClassifierModel() ac.infer_file('audio.wav') # 'Mainstream US English'","title":"Examples"},{"location":"examples/#examples","text":"","title":"Examples"},{"location":"examples/#text-to-speech","text":"from speechtoolkit.tts import SingleSpeakerStyleTTS2Model model = SingleSpeakerStyleTTS2Model() model.infer_to_file('Hello, this is a test', 'out.wav') Multi-speaker StyleTTS 2 with zero-shot voice cloning: from speechtoolkit.tts import MultiSpeakerStyleTTS2Model model = MultiSpeakerStyleTTS2Model() model.infer_to_file('Hello, this is a test', 'sample.wav', 'out.wav')","title":"Text-to-Speech"},{"location":"examples/#automatic-speech-recognition","text":"from speechtoolkit.asr import WhisperModel model = WhisperModel() model.infer_file('audio.wav') With a larger model: from speechtoolkit.asr import WhisperModel model = WhisperModel('medium') model.infer_file('audio.wav') With DistilWhisper: from speechtoolkit.asr import DistilWhisperModel model = DistilWhisperModel() model.infer_file('audio.wav')","title":"Automatic Speech Recognition"},{"location":"examples/#voice-conversion","text":"from speechtoolkit.vc import LVC vc = LVC(device='auto') vc.infer_file( 'original.wav', 'sample.wav', 'out.wav' )","title":"Voice Conversion"},{"location":"examples/#language-classification","text":"from speechtoolkit.classification.languageclassification import WhisperLanguageClassifierModel lc = WhisperLanguageClassifierModel() lc.infer_file('audio.wav') # 'en'","title":"Language Classification"},{"location":"examples/#accent-classification","text":"from speechtoolkit.classification.accentclassification import EdAccAccentClassifierModel ac = EdAccAccentClassifierModel() ac.infer_file('audio.wav') # 'Mainstream US English'","title":"Accent Classification"},{"location":"faqs/","text":"FAQs What is SpeechToolkit? Please refer to the introduction for more details. Are all models trained by SpeechToolkit? No, SpeechToolkit is actually primarily composed of third-party models. SpeechToolkit provides a unified, simple Python API to access these models. However, SpeechToolkit does provide some trained models. Is Apple Silicon (MPS) supported? Unfortunately, PyTorch does not yet support all operations on MPS. For simplicity, MPS support is currently disabled across all models, however it may be supported on a case-by-case basis in the future.","title":"FAQs"},{"location":"faqs/#faqs","text":"","title":"FAQs"},{"location":"faqs/#what-is-speechtoolkit","text":"Please refer to the introduction for more details.","title":"What is SpeechToolkit?"},{"location":"faqs/#are-all-models-trained-by-speechtoolkit","text":"No, SpeechToolkit is actually primarily composed of third-party models. SpeechToolkit provides a unified, simple Python API to access these models. However, SpeechToolkit does provide some trained models.","title":"Are all models trained by SpeechToolkit?"},{"location":"faqs/#is-apple-silicon-mps-supported","text":"Unfortunately, PyTorch does not yet support all operations on MPS. For simplicity, MPS support is currently disabled across all models, however it may be supported on a case-by-case basis in the future.","title":"Is Apple Silicon (MPS) supported?"},{"location":"getting-started/","text":"Getting Started Installation Installing SpeechToolkit is quite easy! Basic Installation Use this for testing, development, etc. Note that it will download packages for all models (text-to-speech, voice cloning, etc), so it will be much slower and larger than downloading task-specific versions. If you're unsure of which one to download, you should use basic installation. pip install speechtoolkit[all] Advanced Installation For production deployment. Install SpeechToolkit core without any extras: pip install speechtoolkit Basic Usage Now that you've successfully installed SpeechToolkit, it's time to run some models! Head over to the examples page to see some basic examples.","title":"Getting Started"},{"location":"getting-started/#getting-started","text":"","title":"Getting Started"},{"location":"getting-started/#installation","text":"Installing SpeechToolkit is quite easy!","title":"Installation"},{"location":"getting-started/#basic-installation","text":"Use this for testing, development, etc. Note that it will download packages for all models (text-to-speech, voice cloning, etc), so it will be much slower and larger than downloading task-specific versions. If you're unsure of which one to download, you should use basic installation. pip install speechtoolkit[all]","title":"Basic Installation"},{"location":"getting-started/#advanced-installation","text":"For production deployment. Install SpeechToolkit core without any extras: pip install speechtoolkit","title":"Advanced Installation"},{"location":"getting-started/#basic-usage","text":"Now that you've successfully installed SpeechToolkit, it's time to run some models! Head over to the examples page to see some basic examples.","title":"Basic Usage"},{"location":"models/","text":"Models SpeechToolkit supports several different models for various tasks. Note that the license \"Same\" indicates that this is Text-to-Speech Below is a list of models supported for text-to-speech: Name License Link StyleTTS 2 MIT Repository Note: StyleTTS 2 by default uses a GPL-licensed phonemizer but we've replaced it with the BSD-licensed OpenPhonemizer . Automatic Speech Recognition Below is a list of supported models for automatic speech recognition. Name License Link Whisper MIT Repository Speech Classification NOTE: Classification models are not very accurate yet. SpeechToolkit supports several different types of speech classification. These models are trained by ML for Speech. Version Task Link V1 Language Classification Model Voice Conversion Below is a list of supported models for voice conversion. Name License Link LVC-VC MIT Repository NS3VC MIT Repository A Short Guide to Licenses Note that this is not legal advice. Please note that models may have a different license than SpeechToolkit. If this is the case, you must comply with both SpeechToolkit and the license of the model. If you're wondering whether or not you can use a model commercially, you should check both the model's license and the pretrained weights' license. The MIT, Apache 2.0, and BSD licenses typically allow commercial use, unless otherwise specified by the authors. However, the BSD-4-Clause license requires you to provide attribution to the author in certain marketing materials (read the full license for details). If the license name includes \"NC,\" it is likely a non-commercial license, which means you cannot use it commercially. Also note that some models may be trained on copyrighted content, which, depending on your jurisdiction, may influence the ability for you to use the models. Before using models, you should carefully read their licenses. Disclaimer Disclaimer for models trained by SpeechToolkit: THE MODEL IS PROVIDED \"AS IS\" AND THE AUTHOR DISCLAIMS ALL WARRANTIES WITH REGARD TO THIS MODEL INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS MODEL.","title":"Models"},{"location":"models/#models","text":"SpeechToolkit supports several different models for various tasks. Note that the license \"Same\" indicates that this is","title":"Models"},{"location":"models/#text-to-speech","text":"Below is a list of models supported for text-to-speech: Name License Link StyleTTS 2 MIT Repository Note: StyleTTS 2 by default uses a GPL-licensed phonemizer but we've replaced it with the BSD-licensed OpenPhonemizer .","title":"Text-to-Speech"},{"location":"models/#automatic-speech-recognition","text":"Below is a list of supported models for automatic speech recognition. Name License Link Whisper MIT Repository","title":"Automatic Speech Recognition"},{"location":"models/#speech-classification","text":"NOTE: Classification models are not very accurate yet. SpeechToolkit supports several different types of speech classification. These models are trained by ML for Speech. Version Task Link V1 Language Classification Model","title":"Speech Classification"},{"location":"models/#voice-conversion","text":"Below is a list of supported models for voice conversion. Name License Link LVC-VC MIT Repository NS3VC MIT Repository","title":"Voice Conversion"},{"location":"models/#a-short-guide-to-licenses","text":"Note that this is not legal advice. Please note that models may have a different license than SpeechToolkit. If this is the case, you must comply with both SpeechToolkit and the license of the model. If you're wondering whether or not you can use a model commercially, you should check both the model's license and the pretrained weights' license. The MIT, Apache 2.0, and BSD licenses typically allow commercial use, unless otherwise specified by the authors. However, the BSD-4-Clause license requires you to provide attribution to the author in certain marketing materials (read the full license for details). If the license name includes \"NC,\" it is likely a non-commercial license, which means you cannot use it commercially. Also note that some models may be trained on copyrighted content, which, depending on your jurisdiction, may influence the ability for you to use the models. Before using models, you should carefully read their licenses.","title":"A Short Guide to Licenses"},{"location":"models/#disclaimer","text":"Disclaimer for models trained by SpeechToolkit: THE MODEL IS PROVIDED \"AS IS\" AND THE AUTHOR DISCLAIMS ALL WARRANTIES WITH REGARD TO THIS MODEL INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS MODEL.","title":"Disclaimer"}]}